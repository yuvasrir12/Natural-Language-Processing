{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2802caeb-de48-4e90-8aa3-105a14542854",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('MT_Eng_Hin_Dataset.txt', encoding= 'utf-8',sep = '\\t', names = ['English','Hindi','Blah'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6848e2de-7a99-45ea-a9b0-8a94787df8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Blah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>If you go to that supermarket, you can buy mos...</td>\n",
       "      <td>उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>The passengers who were injured in the acciden...</td>\n",
       "      <td>जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Democracy is the worst form of government, exc...</td>\n",
       "      <td>लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>If my boy had not been killed in the traffic a...</td>\n",
       "      <td>अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>When I was a kid, touching bugs didn't bother ...</td>\n",
       "      <td>जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                English  \\\n",
       "0                                                  Wow!   \n",
       "1                                                 Duck!   \n",
       "2                                                 Duck!   \n",
       "3                                                 Help!   \n",
       "4                                                 Jump.   \n",
       "...                                                 ...   \n",
       "2974  If you go to that supermarket, you can buy mos...   \n",
       "2975  The passengers who were injured in the acciden...   \n",
       "2976  Democracy is the worst form of government, exc...   \n",
       "2977  If my boy had not been killed in the traffic a...   \n",
       "2978  When I was a kid, touching bugs didn't bother ...   \n",
       "\n",
       "                                                  Hindi  \\\n",
       "0                                                  वाह!   \n",
       "1                                                 झुको!   \n",
       "2                                                 बतख़!   \n",
       "3                                                 बचाओ!   \n",
       "4                                                 उछलो.   \n",
       "...                                                 ...   \n",
       "2974  उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...   \n",
       "2975  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...   \n",
       "2976  लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...   \n",
       "2977  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...   \n",
       "2978  जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...   \n",
       "\n",
       "                                                   Blah  \n",
       "0     CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "1     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "2     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "3     CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "4     CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "...                                                 ...  \n",
       "2974  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "2975  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "2976  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "2977  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "2978  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "\n",
       "[2979 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eef7752-ed59-4187-b2c4-68dbba6a6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Blah',axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b5b4a8-68f5-45c6-bcab-c71e595cd6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English  Hindi\n",
       "0    Wow!   वाह!\n",
       "1   Duck!  झुको!\n",
       "2   Duck!  बतख़!\n",
       "3   Help!  बचाओ!\n",
       "4   Jump.  उछलो."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cc68d3-4e72-4a35-ae51-e83f3db833f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edab0726-12d8-40f8-a1a2-da9a8d8a8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sen = df['English'].to_list()\n",
    "hin_sen = df['Hindi'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236790a2-a536-40cc-8817-03b5cf115d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer()\n",
    "hin_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(eng_sen)\n",
    "hin_tokenizer.fit_on_texts(hin_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b513eb6-02d4-4730-a4f6-9bcbd4d74dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(eng_tokenizer.texts_to_sequences(eng_sen),padding='post')\n",
    "y = pad_sequences(hin_tokenizer.texts_to_sequences(hin_sen),padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c555c9b-b62e-4ad6-bb86-2c42507f90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = min(X.shape[1], y.shape[1])\n",
    "X = X[:, :max_len]\n",
    "y = y[:, :max_len]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d07a679-bf7b-460b-bdd9-f7b8ea9cb3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3044"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hin_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "409b51a3-5ae8-4fcf-a594-eae6dbcc50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuvasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5819 - loss: 4.1825\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6892 - loss: 2.1761\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6907 - loss: 2.1372\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6955 - loss: 2.0999\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6934 - loss: 2.0879\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6939 - loss: 2.0687\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6963 - loss: 2.0450\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6907 - loss: 2.0648\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6973 - loss: 2.0074\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6947 - loss: 2.0381\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6889 - loss: 2.0680\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6972 - loss: 1.9902\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6951 - loss: 2.0066\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6966 - loss: 1.9770\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6962 - loss: 1.9884\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6969 - loss: 1.9982\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6958 - loss: 1.9687\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6957 - loss: 1.9665\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6984 - loss: 1.9602\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7011 - loss: 1.9309\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6984 - loss: 1.9354\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6977 - loss: 1.9478\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6970 - loss: 1.9434\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6995 - loss: 1.9390\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6974 - loss: 1.9394\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6938 - loss: 1.9629\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6984 - loss: 1.9232\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6964 - loss: 1.9275\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7030 - loss: 1.8869\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6944 - loss: 1.9322\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6964 - loss: 1.9255\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6979 - loss: 1.9259\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7014 - loss: 1.8909\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6974 - loss: 1.9138\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6975 - loss: 1.9075\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6983 - loss: 1.9130\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6999 - loss: 1.8996\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6971 - loss: 1.9164\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6992 - loss: 1.8848\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7005 - loss: 1.8848\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6981 - loss: 1.8832\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6964 - loss: 1.9139\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7002 - loss: 1.8780\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6982 - loss: 1.9053\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7000 - loss: 1.9020\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7022 - loss: 1.8806\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6998 - loss: 1.8730\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7011 - loss: 1.8743\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7023 - loss: 1.8635\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7033 - loss: 1.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c5b02fefc0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(32, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "    Dense(len(hin_tokenizer.word_index)+1 , activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), metrics=['accuracy'], loss='sparse_categorical_crossentropy')\n",
    "model.fit(X, y, epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c689b84-4797-466e-b8dd-9d9fc1c177f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translations:\n",
      "English: hello how are you\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Hindi: वह की नहीं करने\n",
      "\n",
      "English: good morning\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Hindi: मैं की\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def translate(text):\n",
    "    sequence = pad_sequences(eng_tokenizer.texts_to_sequences([text]), maxlen=X.shape[1])\n",
    "    prediction = model.predict(sequence.reshape(1, X.shape[1], 1))[0]\n",
    "    return ' '.join([hin_tokenizer.index_word[i] for i in np.argmax(prediction.reshape(-1, len(hin_tokenizer.word_index) + 1), axis=1) if i != 0])\n",
    "'''\n",
    "def translate(text):\n",
    "    # Convert input text to padded sequence\n",
    "    sequence = eng_tokenizer.texts_to_sequences([text])\n",
    "    sequence = pad_sequences(sequence, maxlen=X.shape[1], padding='post')\n",
    "    \n",
    "    # Reshape for the RNN model\n",
    "    sequence = sequence.reshape(1, X.shape[1], 1)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(sequence)[0]\n",
    "\n",
    "    # Get word indices with max probability at each time step\n",
    "    predicted_indices = np.argmax(prediction, axis=1)\n",
    "\n",
    "    # Convert indices to words, skip 0 (padding)\n",
    "    words = [hin_tokenizer.index_word.get(i, '') for i in predicted_indices if i != 0]\n",
    "    \n",
    "    return ' '.join(words).strip()\n",
    "\n",
    "# Test\n",
    "print(\"\\nTranslations:\")\n",
    "for text in [\"hello how are you\", \"good morning\"]:\n",
    "    print(f\"English: {text}\")\n",
    "    print(f\"Hindi: {translate(text)}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92a01f-08c1-49b3-9072-1c262f676b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
